{"cells":[{"cell_type":"code","execution_count":87,"id":"21f4ccac-debd-4814-8da9-45916ead73b0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"21f4ccac-debd-4814-8da9-45916ead73b0","executionInfo":{"status":"ok","timestamp":1745357888687,"user_tz":240,"elapsed":744,"user":{"displayName":"Sophia Zhang","userId":"15534676647975231170"}},"outputId":"a2bebe98-05a8-4296-b345-0a267d12cd93"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","âš ï¸ Playlist link detected and skipped: https://www.youtube.com/watch?v=IhgxZ8tmBxU&list=RDIhgxZ8tmBxU&start_radio=1&pp=oAcB\n","âš ï¸ Playlist link detected and skipped: https://www.youtube.com/watch?v=KDorKy-13ak&list=RDKDorKy-13ak&start_radio=1&pp=oAcB\n","âš ï¸ Playlist link detected and skipped: https://www.youtube.com/watch?v=V1bFr2SWP1I&list=RDV1bFr2SWP1I&start_radio=1&pp=oAcB\n","âš ï¸ Playlist link detected and skipped: https://www.youtube.com/watch?v=TvKJ7uvQPfg&list=RDTvKJ7uvQPfg&start_radio=1&pp=oAcB\n","âš ï¸ Playlist link detected and skipped: https://www.youtube.com/watch?v=7jjcAuEYW9M&list=RD7jjcAuEYW9M&start_radio=1&pp=oAcB\n","âš ï¸ Playlist link detected and skipped: https://www.youtube.com/watch?v=Ru4a-js4My4&list=RDRu4a-js4My4&start_radio=1&pp=oAcB\n","âš ï¸ Playlist link detected and skipped: https://www.youtube.com/watch?v=ZlDeUVvtsZ4&list=RDZlDeUVvtsZ4&start_radio=1&pp=oAcB\n","âš ï¸ Playlist link detected and skipped: https://www.youtube.com/watch?v=ZlDeUVvtsZ4&list=RDZlDeUVvtsZ4&start_radio=1&pp=oAcB\n","âš ï¸ Playlist link detected and skipped: https://www.youtube.com/watch?v=paHE4L-x490&list=RDpaHE4L-x490&start_radio=1&pp=oAcB\n","âš ï¸ Playlist link detected and skipped: https://www.youtube.com/watch?v=4XNG7tmIQx4&list=RDMM&start_radio=1&rv=MtN1YnoL46Q\n","âš ï¸ Playlist link detected and skipped: https://www.youtube.com/watch?v=1EORbL8N-R8&list=RD1EORbL8N-R8&start_radio=1&rv=MtN1YnoL46Q\n","âš ï¸ Playlist link detected and skipped: https://www.youtube.com/watch?v=xJLtzPNxEhw&list=RDxJLtzPNxEhw&start_radio=1&pp=oAcB0gcJCX4JAYcqIYzv\n","âš ï¸ Playlist link detected and skipped: https://www.youtube.com/watch?v=Fp5ghKduTK8&list=RDFp5ghKduTK8&start_radio=1&pp=oAcB\n","âš ï¸ Playlist link detected and skipped: https://www.youtube.com/watch?v=xhrE4M8J3FU&list=RDxhrE4M8J3FU&start_radio=1&pp=oAcB\n","âš ï¸ Playlist link detected and skipped: https://www.youtube.com/watch?v=TvKJ7uvQPfg&list=RDTvKJ7uvQPfg&start_radio=1&pp=oAcB\n","âœ… Exported 823 records to /content/drive/My Drive/YouTube API/Results/mixed_output.csv\n"]}],"source":["#@title YouTube Video Analysis Tool { run: \"auto\" }\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import requests\n","import re\n","import json\n","import random\n","import time\n","import asyncio\n","import aiohttp\n","from typing import List\n","from urllib.parse import urlparse, parse_qs\n","import nest_asyncio\n","import os\n","import nest_asyncio\n","nest_asyncio.apply()\n","\n","\n","# YouTube API Key (replace with your own or set via environment variable)\n","#API_KEY = \"YOUR_API_KEY_HERE\"  #@param {type:\"string\"}\n","API_KEY = \"AIzaSyBZN7PacI6vuj9OCouinWbLVq_GviUbzgg\"\n","YOUTUBE_API_URL = \"https://www.googleapis.com/youtube/v3/videos\"\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","#folder_path = \"/content/drive/My Drive/YouTube API\"\n","\n","# YouTube Category Mapping\n","CATEGORY_MAP = {\n","    \"1\": \"Film & Animation\", \"2\": \"Autos & Vehicles\", \"10\": \"Music\", \"15\": \"Pets & Animals\",\n","    \"17\": \"Sports\", \"18\": \"Short Movies\", \"19\": \"Travel & Events\", \"20\": \"Gaming\",\n","    \"21\": \"Videoblogging\", \"22\": \"People & Blogs\", \"23\": \"Comedy\", \"24\": \"Entertainment\",\n","    \"25\": \"News & Politics\", \"26\": \"Howto & Style\", \"27\": \"Education\", \"28\": \"Science & Technology\",\n","    \"29\": \"Nonprofits & Activism\", \"30\": \"Movies\", \"31\": \"Anime/Animation\", \"32\": \"Action/Adventure\",\n","    \"33\": \"Classics\", \"34\": \"Comedy\", \"35\": \"Documentary\", \"36\": \"Drama\", \"37\": \"Family\",\n","    \"38\": \"Foreign\", \"39\": \"Horror\", \"40\": \"Sci-Fi/Fantasy\", \"41\": \"Thriller\", \"42\": \"Shorts\",\n","    \"43\": \"Shows\", \"44\": \"Trailers\",\n","}\n","\n","# Colab Form Parameters\n","google_drive_data_folder = \"/content/drive/My Drive/YouTube API/Data\" #@param {type:\"string\"}\n","google_drive_results_folder = \"/content/drive/My Drive/YouTube API/Results\" #@param {type:\"string\"}\n","scrape = False  #@param {type:\"boolean\"}\n","keyword = \"duck song\"  #@param {type:\"string\"}\n","max_links = 20 #@param {type:\"integer\"}\n","fetch = True  #@param {type:\"boolean\"}\n","links_mode = \"mixed\"  #@param [\"personalized\", \"non-personalized\", \"mixed\"]\n","links_file = \"Clean STAT 1001 Youtube Experiment.csv\"  #@param {type:\"string\"}\n","output_csv = \"mixed_output.csv\"  #@param [\"non_personalized_output.csv\", \"personalized_output.csv\", \"mixed_output.csv\"]\n","analyze = False  #@param {type:\"boolean\"}\n","csv_file = \"non_personalized_output.csv\"  #@param {type:\"string\"}\n","output_png = \"non_personalized_output.png\"  #@param [\"non_personalized_output.png\", \"personalized_output.png\", \"mixed_output.png\"]\n","example = False  #@param {type:\"boolean\"}\n","\n","def extract_video_id(link: str) -> str:\n","    \"\"\"Extract video ID from a YouTube link, skipping playlists.\"\"\"\n","    parsed = urlparse(link)\n","    if \"list\" in parse_qs(parsed.query):\n","        print(f\"âš ï¸ Playlist link detected and skipped: {link}\")\n","        return \"\"\n","    if parsed.hostname == \"youtu.be\":\n","        return parsed.path.lstrip(\"/\")\n","    query = parse_qs(parsed.query)\n","    return query.get(\"v\", [\"\"])[0]\n","\n","def batch_video_ids(video_links: List[str], batch_size: int = 50):\n","    \"\"\"Batch video links into smaller groups for API requests.\"\"\"\n","    for i in range(0, len(video_links), batch_size):\n","        yield video_links[i:i + batch_size]\n","\n","async def fetch_video_metadata(session: aiohttp.ClientSession, video_links: List[str], api_key: str):\n","    \"\"\"Fetch metadata for a batch of YouTube videos asynchronously.\"\"\"\n","    video_ids = [extract_video_id(link) for link in video_links]\n","    if not video_ids:\n","        return []\n","\n","    params = {\"part\": \"snippet\", \"id\": \",\".join(video_ids), \"key\": api_key}\n","    try:\n","        async with session.get(YOUTUBE_API_URL, params=params) as resp:\n","            if resp.status != 200:\n","                print(f\"API request failed with status {resp.status}\")\n","                return []\n","            data = await resp.json()\n","            results = []\n","            for item in data.get(\"items\", []):\n","                video_id = item.get(\"id\")\n","                snippet = item.get(\"snippet\", {})\n","                title = snippet.get(\"title\")\n","                category_id = snippet.get(\"categoryId\")\n","                category = CATEGORY_MAP.get(category_id, \"Unknown\")\n","                url = f\"https://www.youtube.com/watch?v={video_id}\"\n","                results.append({\n","                    \"video_id\": video_id, \"title\": title, \"category_id\": category_id,\n","                    \"category\": category, \"url\": url\n","                })\n","            return results\n","    except Exception as e:\n","        print(f\"Error fetching metadata: {e}\")\n","        return []\n","\n","async def get_video_data_to_csv(video_links: List[str], output_csv: str = \"video_data.csv\"):\n","    \"\"\"Fetch video data and save it to a CSV file.\"\"\"\n","    async with aiohttp.ClientSession() as session:\n","        tasks = [fetch_video_metadata(session, batch, API_KEY) for batch in batch_video_ids(video_links)]\n","        all_results = await asyncio.gather(*tasks)\n","        flat_results = [item for batch in all_results for item in batch]\n","        df = pd.DataFrame(flat_results)\n","        df.to_csv(output_csv, index=False)\n","        print(f\"âœ… Exported {len(df)} records to {output_csv}\")\n","        return df\n","\n","def scrape_youtube_links(keyword: str, max_links: int) -> List[str]:\n","    \"\"\"Scrape YouTube video links based on a keyword.\"\"\"\n","    search_url = f\"https://www.youtube.com/results?search_query={keyword}\"\n","    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n","    response = requests.get(search_url, headers=headers)\n","    match = re.search(r\"var ytInitialData = ({.*?});</script>\", response.text)\n","    if not match:\n","        print(f\"No ytInitialData found for keyword: {keyword}\")\n","        return []\n","    try:\n","        data = json.loads(match.group(1))\n","        video_ids = set()\n","        contents = data[\"contents\"][\"twoColumnSearchResultsRenderer\"][\"primaryContents\"][\"sectionListRenderer\"][\"contents\"]\n","        for section in contents:\n","            items = section.get(\"itemSectionRenderer\", {}).get(\"contents\", [])\n","            for item in items:\n","                video = item.get(\"videoRenderer\")\n","                if video and \"videoId\" in video:\n","                    video_id = video[\"videoId\"]\n","                    video_ids.add(f\"https://www.youtube.com/watch?v={video_id}\")\n","                    if len(video_ids) >= max_links:\n","                        return list(video_ids)\n","        return list(video_ids)\n","    except Exception as e:\n","        print(f\"Error parsing data for keyword {keyword}: {e}\")\n","        return []\n","\n","def get_random_youtube_links(total_needed: int = 600) -> List[str]:\n","    \"\"\"Generate a specified number of random YouTube video links.\"\"\"\n","    all_links = set()\n","    attempts = 0\n","    while len(all_links) < total_needed and attempts < 100:\n","        keyword = \"\".join(random.choices(\"abcdefghijklmnopqrstuvwxyz\", k=3))\n","        print(f\"[{len(all_links)}/{total_needed}] Searching: {keyword}\")\n","        new_links = scrape_youtube_links(keyword, max_links=50)\n","        all_links.update(new_links)\n","        attempts += 1\n","        time.sleep(0.5)  # Polite delay to avoid overwhelming the server\n","    return list(all_links)[:total_needed]\n","\n","def find_top_category(csv_file: str):\n","    \"\"\"Analyze and visualize category distribution from a CSV file.\"\"\"\n","    df = pd.read_csv(csv_file)\n","    category_counts = df[\"category\"].value_counts().sort_values(ascending=False)\n","    print(f\"\\nCategory distribution for {csv_file}:\\n{category_counts}\")\n","\n","    plt.figure(figsize=(10, 6))\n","    category_counts.plot(kind=\"bar\", color=\"skyblue\", edgecolor=\"black\")\n","    plt.title(f\"Video Counts by Category ({csv_file})\", fontsize=16)\n","    plt.xlabel(\"Category\", fontsize=12)\n","    plt.ylabel(\"Count\", fontsize=12)\n","    plt.xticks(rotation=45, ha=\"right\")\n","    for i, count in enumerate(category_counts):\n","        plt.text(i, count + 0.2, str(count), ha=\"center\", va=\"bottom\")\n","    plt.tight_layout()\n","    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n","\n","    output = os.path.join(google_drive_results_folder, \"category_dist_\"+output_png)\n","    plt.savefig(output)\n","    print(f\"ðŸ“Š Plot saved to: {output}\")\n","\n","    plt.show()\n","    plt.close()\n","\n","\n","async def run_example_analysis():\n","    \"\"\"Run a full example analysis with toy links and random links.\"\"\"\n","    print(\"\\nRunning example analysis...\")\n","\n","    # 1. Toy links\n","    toy_links = [\n","        \"https://www.youtube.com/watch?v=MtN1YnoL46Q\",\n","        \"https://www.youtube.com/watch?v=N2HQaQJsyQ4\",\n","        \"https://www.youtube.com/watch?v=IJNR2EpS0jw\",\n","         # debug personal->Duck Song2->Comedy\n","        \"https://www.youtube.com/watch?v=7jjcAuEYW9M\",\n","         # original duck song\n","         \"https://www.youtube.com/watch?v=MtN1YnoL46Q\",\n","         # additional testing on Duck Song 1-7\n","         \"https://www.youtube.com/watch?v=7wWJJtIbiHk\",\n","         # bad playlist -> warning + delete\n","         \"https://youtube.com/playlist?list=RDEMVdIAVFQ0_mzQJ5fQjBa7HQ&playnext=1&si=8oPmUNKvvGjWh29m\",\n","         # invalid link -> delete\n","         \"https://www.youtube.com/watch?v=notexisthahaha\"\n","         # youtube category checker to confirm correctness\n","         # https://tubepilot.ai/tools/youtube-category-checker/\n","    ]\n","\n","    print(\"Processing toy links...\")\n","    await get_video_data_to_csv(toy_links, os.path.join(google_drive_results_folder,\"toy_output.csv\"))\n","\n","    # 2. Random YouTube links\n","    print(\"Generating random YouTube links...\")\n","    random_links = get_random_youtube_links(100)\n","    await get_video_data_to_csv(random_links, os.path.join(google_drive_results_folder,\"random_output.csv\"))\n","\n","async def main():\n","    \"\"\"Main function to handle form inputs and run selected actions.\"\"\"\n","    if scrape:\n","        if not keyword:\n","            print(\"Error: Scraping requires a keyword\")\n","            return\n","        print(f\"Scraping up to {max_links} links for keyword: {keyword}\")\n","        links = scrape_youtube_links(keyword, max_links)\n","        print(f\"Scraped {len(links)} links: {links[:5]}... (showing first 5)\")\n","    elif fetch:\n","        full_links_file = os.path.join(google_drive_data_folder, links_file)\n","        full_output_csv = os.path.join(google_drive_results_folder, output_csv)\n","        if not links_file:\n","            print(\"Error: Fetching metadata requires a links file\")\n","            return\n","        if not os.path.exists(full_links_file):\n","            print(f\"Error: File {full_links_file} not found\")\n","            return\n","        df = pd.read_csv(full_links_file)\n","\n","        # Directly handle the links based on the mode\n","        if links_mode == \"personalized\":\n","            video_links = df.iloc[:, 1:11].values.flatten()\n","        elif links_mode == \"non-personalized\":\n","            video_links = df.iloc[:, 11:21].values.flatten()\n","        else:  # 'mixed'\n","            video_links = list(df.iloc[:, 1:11].values.flatten()) + list(df.iloc[:, 11:21].values.flatten())\n","\n","        asyncio.run(get_video_data_to_csv(video_links, full_output_csv))\n","        #await get_video_data_to_csv(video_links, output_csv)\n","    elif analyze:\n","        full_csv_file = os.path.join(google_drive_data_folder, csv_file)\n","        if not csv_file:\n","            print(\"Error: Analyzing requires a CSV file\")\n","            return\n","        if not os.path.exists(full_csv_file):\n","            print(f\"Error: File {full_csv_file} not found\")\n","            return\n","        find_top_category(full_csv_file)\n","    elif example:\n","        asyncio.run(run_example_analysis())\n","    else:\n","        print(\"No action selected. Please set one of the options.\")\n","\n","# Run the main function\n","await main()"]},{"cell_type":"code","execution_count":null,"id":"4b27f823-7704-4ab2-9383-db5f1a68a95d","metadata":{"id":"4b27f823-7704-4ab2-9383-db5f1a68a95d"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}